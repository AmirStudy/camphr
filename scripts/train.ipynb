{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedoner.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedoner.ner_labels.utils import make_biluo_labels\n",
    "from bedoner.ner_labels.labels_irex import ALL_LABELS\n",
    "from spacy.util import minibatch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "with (Path.home() / \"datasets/ner/gsk-ene-1.1-bccwj/irex/irex-positive.jsonl\").open() as f:\n",
    "    for i,line in enumerate(f):\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain, neval=100,100\n",
    "random.shuffle(data)\n",
    "train_data=data[:ntrain]\n",
    "val_data=data[-neval:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=bert_ner(labels=make_biluo_labels(ALL_LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.gold import spans_from_biluo_tags, GoldParse\n",
    "from itertools import zip_longest\n",
    "\n",
    "def is_same(ents1, ents2):\n",
    "    for e, e2 in zip_longest(ents1,ents2):\n",
    "        if e != e2:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "texts, golds = zip(*val_data)\n",
    "def val(nlp):\n",
    "    docs=list(nlp.pipe(texts))\n",
    "    gs=[GoldParse(doc, **gold) for doc,gold in zip(docs,golds)]\n",
    "    entsl=[spans_from_biluo_tags(doc,g.ner) for g,doc in zip(gs,docs)]\n",
    "    return sum(is_same(doc.ents, ents) for doc, ents in zip(docs,entsl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter=5\n",
    "nbatch=16\n",
    "ndata=ntrain\n",
    "optim=nlp.resume_training(t_total=niter, enable_scheduler=False)\n",
    "for i in range(niter):\n",
    "    random.shuffle(train_data)\n",
    "    epoch_loss=0\n",
    "    for i,batch in enumerate(minibatch(train_data, size=nbatch)):\n",
    "        texts, golds=zip(*batch)\n",
    "        docs=[nlp.make_doc(text) for text in texts]\n",
    "        nlp.update(docs, golds,optim)\n",
    "        epoch_loss+=sum(doc._.loss for doc in docs)\n",
    "        loss = sum(doc._.loss.detach().item() for doc in docs)\n",
    "        print(f\"{i*nbatch}/{ndata} loss: {loss}\")\n",
    "        if i % 10 == 9:\n",
    "            acc = val(nlp)\n",
    "            print(f\"epoch {i} val: \", acc /neval)\n",
    "    print(f\"epoch {i} loss: \", epoch_loss)\n",
    "    nlp.to_disk(f\"irex{i}\")\n",
    "    losses.append(epoch_loss)\n",
    "    print(epoch_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedoner",
   "language": "python",
   "name": "bedoner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
